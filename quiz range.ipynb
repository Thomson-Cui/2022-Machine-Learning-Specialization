{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31280828",
   "metadata": {},
   "source": [
    "- Functions taking multiple inputs are called `Multivariate functions`. The symbol × indicates the `Cartesian product`.\n",
    "- Functions producing multiple outputs are called `Vector Function`.\n",
    "- When a function takes multiple inputs, we compute `partial derivatives` by varying each input and holding the others `fixed`. A function with m inputs will have `m partial` derivatives.\n",
    "- The `row vector` containing all `partial derivatives` is called the `Jacobian` of the function.\n",
    "- A vector function can be viewed as a `vector of scalar` functions.\n",
    "- The `Jacobian` of a vector function is a `column vector`.\n",
    "- The `Jacobian` of a multivariate vector function with n inputs and m outputs is a `matrix` of size `m × n`.\n",
    "- The partial derivative of $f(g(x, y))$ with respect to $x$ is: $\\frac{\\partial f}{\\partial g} \\cdot \\frac{\\partial g}{\\partial x}$. This is the partial derivative **`chain rule`**.\n",
    "- The second derivative is the `rate of change` of the `slope` around a point. Geometrically, this refers to the **`curvature`** of a function. If positive, the function looks like a `cup` (concave up), and if negative, it looks like a `cap` (concave down).\n",
    "- For a function taking m inputs, the Jacobian can be interpreted as a `multivariate vector function` taking `m` inputs and producing `n` outputs, where `n` is the number of outputs of the original vector function.\n",
    "- For a multivariate function with *n* inputs, the second derivative is a `matrix` of size **$(n, n)$**. It is called the **`Hessian matrix`**.\n",
    "- If the input is a multivariate vector function, the `Hessian matrix` is a `multi-dimensional matrix`. These are called `tensors`.\n",
    "- In practice, we sometimes convert a `tensor` into a matrix or vector. This is called `reshaping`.\n",
    "- In an optimization problem, we look for the `extreme values` of a function. Sometimes we look for “argmin” or “argmax,” which are the arguments (Objective function) that minimize or maximize the function, respectively.\n",
    "- Optimization problems can be `discrete` or `continuous`. They can also be `constrained` or `unconstrained`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb60567",
   "metadata": {},
   "source": [
    "- To minimize a function, the `Jacobian` has to be `zero`, and the `Hessian` has to be `positive definite`.\n",
    "- Iterative Optimization\n",
    "    - Initialize the `solution candidate` with a `random guess` $x$\n",
    "    - Until we find the maximum or minimum (“`convergence`”) loop:\n",
    "        1. Choose a direction $d$\n",
    "        2. Choose a stepsize $\\lambda$\n",
    "        3. $x\\leftarrow x+\\lambda d$\n",
    "        4. Check: are we at min or max f(x)\n",
    "            - By evaluating $\\frac{df}{dx}=0$ at current guess, and ensuring $\\frac{d^2f}{dx^2}\\geq 0$ (min) or $\\frac{d^2f}{dx^2}\\leq 0$ (max)\n",
    "            - In a computer, always check $|\\frac{df}{dx}|\\leq\\epsilon$, like 1e-6\n",
    "- Gradient ascent takes a small step in the `uphill` direction.\n",
    "- Why does the step need to be small?\n",
    "    - A small step helps ensure that `the updates` to the solution are `stable` and the algorithm `converges` to the local maximum or minimum instead of `overshooting` it.\n",
    "- Convergence is usually slow with gradient ascent/descent, because `the step size may be too small`, leading to `tiny updates in each iteration`.\n",
    "-  The Newton-Raphson method approximates the function locally as a `quadratic`.\n",
    "    - This provides `faster rates of convergence than gradient descent`, but may `diverge` in some cases `if started far from the solution`.\n",
    "- What is a quasi-Newton method?\n",
    "    - A quasi-Newton method is an `optimization algorithm` that `builds upon the Newton-Raphson method` by `approximating the Hessian matrix` (the matrix of second derivatives) `rather than computing it directly`, leading to faster convergence rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391285a1",
   "metadata": {},
   "source": [
    "- A set $C$ is convex set if for any $x_1, x_2$ in $C$, $\\lambda x_1 + (1−\\lambda) x_2,\\,\\lambda\\in[0,1]$ is also in $C$.\n",
    "- A convex function is a function whose `epigraph` is convex set.\n",
    "- Convex functions satisfy the `Jensen's inequality`.\n",
    "- For convex functions, every `local optimum` is a `global optimum`.\n",
    "- The constraints optimization define a `feasible region` where `the solution must lie`.\n",
    "- In a linear program, the feasible region is a **`polyhedron`**, and the solution lies at a `vertex`.\n",
    "- From a primal linear program, we can create a `dual` LP (linear program).\n",
    "- The conditions for optimality of a primal-dual convex system are given by the **Karush-Kuhn-Tucker (KKT)** conditions.\n",
    "- What is “integrate and fire” in an actual neuron?\n",
    "    - In a perceptron, there are `input` units and an `output` unit. Each input has a weight associated with it. If `the dot product` between `inputs and weights` is `greater` than `the activation threshold`, the perceptron will `fire`.\n",
    "- The perceptron is a `parametric` model. The parameters are `the weights and the bias`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5cdb1",
   "metadata": {},
   "source": [
    "- To estimate perceptron parameters, we define a `loss function` that `measures` the `difference` between our `estimated labels` and `the true labels`.\n",
    "- The gradient descent procedure will `converge to a global minimum` because `the loss function is convex`.\n",
    "- We can also use `stochastic gradient descent`. This is different from regular gradient descent because it `updates the model parameters` using `a small batch` at each iteration, `rather than using the entire dataset`. This can lead to `faster convergence`, especially for `large datasets`.\n",
    "    - SGD is useful if the function has multiple **`local optimal`**. It can also be used during `online learning`.\n",
    "- The `XOR` function cannot be learned with a perceptron, because the XOR function is `not linearly separable`.\n",
    "- Every Boolean function can be represented by a network with `one` hidden layer.\n",
    "- Every bounded continuous function can be represented by a network with `one` hidden layers.\n",
    "- Every function on $R^n$ can be represented by a network with `two` hidden layers!\n",
    "- The tradeoffs\n",
    "    - Increased Complexity of model\n",
    "    - Longer Training Time\n",
    "    - Structure and function relationship are uninterpretable sometimes.\n",
    "- The activation functions in an ANN must be `non-linear` for learning.\n",
    "- The sigmoid function: $\\sigma(x)=\\frac{1}{1+e^{-x}}$\n",
    "- Backpropagation performs `layer-wise` gradient descent. First, information flows `forward` through the network to compute the `output`. Then, the `loss` flows backward to compute the `gradients`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ab61a6",
   "metadata": {},
   "source": [
    "- Convolution is a `linear` operation. The `kernel` can be learned from `data`.\n",
    "- A tensor is a `multi-dimensional array`. It is used to preserve `locality` across layers.\n",
    "- A pooling layer `aggregates information` from adjacent layers.\n",
    "- Deep NNs suffer from the `vanishing gradient` problem.\n",
    "- In a **recurrent** network, the learned representation at each layer is a **projection** of the previous.\n",
    "- One way to control overfitting in ANNs is to use `weight decay`. This adds a `cost penalty` to the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526d7e0",
   "metadata": {},
   "source": [
    "1. Why might we need many layers?\n",
    "    - if not, they will need many **nodes** and not have **structure** to exploit. \n",
    "    - networks with more layers perform better\n",
    "    - **Cascade Correlation** creates a deep architecture by successively learning **predictors**, each modeling the **residuals** of the previous. \n",
    "    - One way to interpret hidden units is as **feature constructors** for a **high dimensional space** where classification can be done with a **perceptron**. \n",
    "    - Each layer then is an **abstraction**---a feature constructor that builds on previous features\n",
    "\n",
    "2. What should all these layers do?\n",
    "    - To generate good features, we should allow **long computational paths** \n",
    "    - We should also **aggregate information** across different parts of the input. \n",
    "- Neural Networks can be viewed as **computation graphs**. Each layer of a network performs a **matrix** operation on the input **vector**. \n",
    "- Fully connected layers can be problematic because the number of weights **grow quadratically**. \n",
    "3. Locality and Invariance\n",
    "    - Let each hidden unit only look at a local part of the input (Locality)\n",
    "    - Let different hidden units compute the same feature for different local regions (Invariance)\n",
    "- In a **convolutional neural network**, we introduce a **kernel**: a set of weights replicated across multiple local regions of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08a2d5",
   "metadata": {},
   "source": [
    "- One way to control overfitting is to use **dropout**. Here a **random sample** of the nodes is left out during **backpropogation**.\n",
    "- It is useful to **standardize** the inputs to an ANN. When done at internal nodes this is called **batch normalization**\n",
    "- Nominal features have to be encoded via **one-hot encoding** or **label encoding** when input to an ANN.\n",
    "- Probabilistic classifiers are useful to determine the optimal hypothesis using **Bayesian Decision Theory**\n",
    "- They also incorporate **prior knowledge** and produce **confidence* *estimates.\n",
    "- They can be **generative** or **discriminative**. The first models **joint probabilities of features and labels**, the second **directly models the conditional probability of a label given the features**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
